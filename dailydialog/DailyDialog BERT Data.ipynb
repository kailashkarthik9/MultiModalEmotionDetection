{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 87,170\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>act</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86419</th>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>What do you think of the acting of the two mai...</td>\n",
       "      <td>relationship</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45619</th>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>What was that ?</td>\n",
       "      <td>ordinary_life</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72424</th>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>Isn't my baggage enough of a deposit ?</td>\n",
       "      <td>tourism</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35739</th>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>After that , we'll let you decide if you still...</td>\n",
       "      <td>ordinary_life</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66114</th>\n",
       "      <td>sadness</td>\n",
       "      <td>inform</td>\n",
       "      <td>Sorry , sir , we are having a sale now .</td>\n",
       "      <td>ordinary_life</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48712</th>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>Good afternoon , Mr . Dome ' s office .</td>\n",
       "      <td>work</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78570</th>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>Good afternoon , ABC Incorporated . How many I...</td>\n",
       "      <td>work</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21959</th>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>In that case , formal suit with a nice tie wil...</td>\n",
       "      <td>relationship</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82333</th>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>Have you received any scholarships ?</td>\n",
       "      <td>work</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12071</th>\n",
       "      <td>anger</td>\n",
       "      <td>directive</td>\n",
       "      <td>Don't brother me !</td>\n",
       "      <td>school_life</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          emotion        act  \\\n",
       "86419  no_emotion   question   \n",
       "45619  no_emotion   question   \n",
       "72424  no_emotion   question   \n",
       "35739  no_emotion     inform   \n",
       "66114     sadness     inform   \n",
       "48712  no_emotion     inform   \n",
       "78570  no_emotion   question   \n",
       "21959  no_emotion     inform   \n",
       "82333  no_emotion   question   \n",
       "12071       anger  directive   \n",
       "\n",
       "                                                    text          topic  label  \n",
       "86419  What do you think of the acting of the two mai...   relationship      3  \n",
       "45619                                    What was that ?  ordinary_life      3  \n",
       "72424             Isn't my baggage enough of a deposit ?        tourism      3  \n",
       "35739  After that , we'll let you decide if you still...  ordinary_life      3  \n",
       "66114           Sorry , sir , we are having a sale now .  ordinary_life      4  \n",
       "48712            Good afternoon , Mr . Dome ' s office .           work      3  \n",
       "78570  Good afternoon , ABC Incorporated . How many I...           work      3  \n",
       "21959  In that case , formal suit with a nice tie wil...   relationship      3  \n",
       "82333               Have you received any scholarships ?           work      3  \n",
       "12071                                 Don't brother me !    school_life      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df_train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"test.csv\", index_col=0)\n",
    "df_val = pd.read_csv(\"val.csv\", index_col=0)\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df_train.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = df_train.text.values\n",
    "train_labels = df_train.label.values\n",
    "test_sentences = df_test.text.values\n",
    "test_labels = df_test.label.values\n",
    "val_sentences = df_val.text.values\n",
    "val_labels = df_val.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Say , Jim , how about going for a few beers after dinner ?\n",
      "Tokenized:  ['say', ',', 'jim', ',', 'how', 'about', 'going', 'for', 'a', 'few', 'beers', 'after', 'dinner', '?']\n",
      "Token IDs:  [2360, 1010, 3958, 1010, 2129, 2055, 2183, 2005, 1037, 2261, 18007, 2044, 4596, 1029]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', train_sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(train_sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train sentence length:  296\n",
      "Max test sentence length:  220\n",
      "Max val sentence length:  178\n"
     ]
    }
   ],
   "source": [
    "train_max_len = 0\n",
    "for sent in train_sentences:\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    train_max_len = max(train_max_len, len(input_ids))\n",
    "print('Max train sentence length: ', train_max_len)\n",
    "\n",
    "test_max_len = 0\n",
    "for sent in test_sentences:\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    test_max_len = max(test_max_len, len(input_ids))\n",
    "print('Max test sentence length: ', test_max_len)\n",
    "\n",
    "val_max_len = 0\n",
    "for sent in val_sentences:\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    val_max_len = max(val_max_len, len(input_ids))\n",
    "print('Max val sentence length: ', val_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "for sent in train_sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                        truncation=True\n",
    "                   )\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "for sent in test_sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                        truncation=True\n",
    "                   )\n",
    "    test_input_ids.append(encoded_dict['input_ids'])\n",
    "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "for sent in val_sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                        truncation=True\n",
    "                   )\n",
    "    val_input_ids.append(encoded_dict['input_ids'])\n",
    "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "val_labels = torch.tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, 'train_dataset.pt')\n",
    "torch.save(test_dataset, 'test_dataset.pt')\n",
    "torch.save(val_dataset, 'val_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
